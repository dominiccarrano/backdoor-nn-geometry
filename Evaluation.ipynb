{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import os\n",
    "from attack_functions import *\n",
    "from trojai_utils import *\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_TRAIN = pd.read_csv(\"place where training set's METADATA.csv is\")\n",
    "METADATA_TEST = pd.read_csv(\"place where test set's METADATA.csv is\")\n",
    "METADATA_HOLDOUT = pd.read_csv(\"place where holdout set's METADATA.csv is\")\n",
    "TRAIN_RESULTS_PATH = \"place where your train results from trojai_runner.py were saved to\"\n",
    "TEST_RESULTS_PATH = \"place where your test results from trojai_runner.py were saved to\"\n",
    "HOLDOUT_RESULTS_PATH = \"place where your holdout results from trojai_runner.py were saved to\"\n",
    "\n",
    "THICK_NAMES = [\"clean\", \"adv+to-\", \"adv-to+\", \"uap+to-\", \"uap-to+\"]\n",
    "TILT_NAMES = [\"adv_adv+to-\", \"adv_adv-to+\", \"uap_uap+to-\", \"uap_uap-to+\"]\n",
    "FEATURE_QUANTILES = [0, 1]\n",
    "\n",
    "embedding_codes = {\"BERT\": 0, \"DistilBERT\": 1, \"GPT-2\": 2}\n",
    "embedding_lookups = {0: \"BERT\", 1: \"DistilBERT\", 2: \"GPT-2\"}\n",
    "architecture_codes = {\"LstmLinear\": 0, \"GruLinear\": 1}\n",
    "architecture_lookups = { 0: \"LstmLinear\", 1: \"GruLinear\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(results_path, embed, arch, model_id, which):\n",
    "    with torch.no_grad():\n",
    "        thicks, tilts, losses = [], [], []\n",
    "        for suffix in THICK_NAMES:\n",
    "            thicks.append(torch.load(os.path.join(results_path, embed, arch, \n",
    "                                                  which + suffix + \"_thickness{}.pt\".format(model_id))))\n",
    "        for suffix in TILT_NAMES:\n",
    "            tilts.append(torch.load(os.path.join(results_path, embed, arch, \n",
    "                                                 which + suffix + \"_tilting{}.pt\".format(model_id))))\n",
    "        for suffix in LOSS_NAMES:\n",
    "            losses.append(torch.load(os.path.join(results_path, embed, arch,\n",
    "                                                  which + \"_{0}{1}.pt\".format(suffix, model_id))))\n",
    "    return thicks, tilts, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_thick_features(thicks):\n",
    "    thick_features = []\n",
    "    for thick_direction in thicks:\n",
    "        for i in [1, 2]: \n",
    "            thickness_dist = thick_direction[i] \n",
    "            thickness_dist = thickness_dist[thickness_dist > 0].detach().clone().cpu() # filter out 0's\n",
    "            thick_features.append(quantile_features(thickness_dist, FEATURE_QUANTILES).numpy())\n",
    "            thick_features.append(moment_features(thickness_dist).numpy())\n",
    "    return np.concatenate(thick_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tilt_features(tilts):\n",
    "    tilt_features = []\n",
    "    for tilting_dist in tilts:\n",
    "        tilting_dist = tilting_dist.detach().clone().cpu()\n",
    "        tilt_features.append(quantile_features(tilting_dist, FEATURE_QUANTILES).numpy())\n",
    "        tilt_features.append(moment_features(tilting_dist).numpy())\n",
    "    return np.concatenate(tilt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(results_path, embed, arch, add_embed_feat, add_arch_feat, METADATA):\n",
    "    clean_model_ids = METADATA.index[(METADATA.embedding==embed) & (METADATA.model_architecture==arch) & (METADATA.poisoned==False)].tolist()\n",
    "    poisoned_model_ids = METADATA.index[(METADATA.embedding==embed) & (METADATA.model_architecture==arch) & (METADATA.poisoned==True)].tolist()\n",
    "    \n",
    "    # Load data\n",
    "    clean_features, poisoned_features = [], []\n",
    "    for model_id in clean_model_ids:\n",
    "        try:\n",
    "            thicks, tilts, losses = load_all(results_path, embed, arch, model_id, \"clean\")\n",
    "        except FileNotFoundError:\n",
    "            print(model_id)\n",
    "            continue\n",
    "        thick_feats, tilt_feats = make_thick_features(thicks), make_tilt_features(tilts)\n",
    "        clean_features.append(np.concatenate((thick_feats, tilt_feats, losses)))\n",
    "            \n",
    "    for model_id in poisoned_model_ids:\n",
    "        try:\n",
    "            thicks, tilts, losses = load_all(results_path, embed, arch, model_id, \"poisoned\")\n",
    "        except FileNotFoundError:\n",
    "            print(model_id)\n",
    "            continue\n",
    "        thick_feats, tilt_feats = make_thick_features(thicks), make_tilt_features(tilts)\n",
    "        poisoned_features.append(np.concatenate((thick_feats, tilt_feats, losses)))\n",
    "    \n",
    "    # Build data matrix\n",
    "    clean_features, poisoned_features = np.array(clean_features), np.array(poisoned_features)\n",
    "    n_clean, n_poisoned = clean_features.shape[0], poisoned_features.shape[0]    \n",
    "    X = np.concatenate((clean_features, poisoned_features), axis=0)\n",
    "    y = np.concatenate((np.zeros(n_clean), np.ones(n_poisoned)))\n",
    "    \n",
    "    # Add categorical features\n",
    "    if add_embed_feat:\n",
    "        X = np.concatenate((X, embedding_codes[embed] * np.ones((X.shape[0], 1))), axis=1)\n",
    "    if add_arch_feat:\n",
    "        X = np.concatenate((X, architecture_codes[arch] * np.ones((X.shape[0], 1))), axis=1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_X_y(results_path, metadata):\n",
    "    with torch.no_grad():\n",
    "        X, y = [], []\n",
    "        feature_names = []\n",
    "        for embed in [\"BERT\", \"DistilBERT\", \"GPT-2\"]:\n",
    "            for arch in [\"LstmLinear\", \"GruLinear\"]:\n",
    "                X_cache = []\n",
    "                curr_X, curr_y = make_data(results_path, embed, arch, True, True, metadata)\n",
    "                X_cache.append(curr_X)\n",
    "                X.append(np.concatenate(X_cache, axis=1))\n",
    "                y.append(curr_y)\n",
    "\n",
    "        for thick_name in THICK_NAMES:\n",
    "            for ab_str in [\"0_0.75\", \"0_1\"]:\n",
    "                for q in FEATURE_QUANTILES:\n",
    "                    feature_names.append(\"thick_\" + thick_name + ab_str + \"_q\" + str(q))\n",
    "                for m in range(1, 5):\n",
    "                    feature_names.append(\"thick_\" + thick_name + ab_str + \"_m\" + str(m))\n",
    "        for tilt_name in TILT_NAMES:\n",
    "            for q in FEATURE_QUANTILES:\n",
    "                feature_names.append(\"tilt_\" + tilt_name + \"_q\" + str(q))\n",
    "            for m in range(1, 5):\n",
    "                feature_names.append(\"tilt_\" + tilt_name + \"_m\" + str(m))\n",
    "        for loss_name in LOSS_NAMES:\n",
    "            feature_names.append(\"loss_\" + loss_name)\n",
    "        feature_names.append(\"embedding\")\n",
    "        feature_names.append(\"architecture\")\n",
    "        feature_names = np.array(feature_names)\n",
    "\n",
    "        X = np.concatenate(X, axis=0)\n",
    "        y = np.concatenate(y, axis=0)\n",
    "    return X, y, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y, feature_names = make_full_X_y(TRAIN_RESULTS_PATH, METADATA_TRAIN)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_test, y_test, feature_names = make_full_X_y(TEST_RESULTS_PATH, METADATA_TEST)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "X_holdout, y_holdout, feature_names = make_full_X_y(HOLDOUT_RESULTS_PATH, METADATA_HOLDOUT)\n",
    "print(X_holdout.shape, y_holdout.shape)\n",
    "print(\"Number of features:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest_param_grid = {\"n_estimators\": [64, 128], \"max_depth\": [4, 6, 8]}\n",
    "\n",
    "cv_gbf = GridSearchCV(GradientBoostingClassifier(), forest_param_grid)\n",
    "cv_gbf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbf_final = CalibratedClassifierCV(cv_gbf.best_classifier_, cv=10)\n",
    "gbf_final.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(clf, X_train, y_train, X_test, y_test, X_holdout, y_holdout):\n",
    "    y_test_probs = clf.predict_proba(X_test)\n",
    "    y_holdout_probs = clf.predict_proba(X_holdout)\n",
    "    print(\"Train Accuracy: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    \n",
    "    print(\"Accuracy:  {:.3f} (Test)\\t{:.3f} (Holdout)\".format(clf.score(X_test, y_test), \n",
    "                                                              clf.score(X_holdout, y_holdout)))\n",
    "    \n",
    "    print(\"AUC:       {:.3f} (Test)\\t{:.3f} (Holdout)\".format(roc_auc_score(y_test, y_test_probs[:, 1]),\n",
    "                                                              roc_auc_score(y_holdout, y_holdout_probs[:, 1])))\n",
    "    \n",
    "    print(\"CE:        {:.3f} (Test)\\t{:.3f} (Holdout)\\n\".format(log_loss(y_test, y_test_probs),\n",
    "                                                                log_loss(y_holdout, y_holdout_probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gbf_final, X, y, X_test, y_test, X_holdout, y_holdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
